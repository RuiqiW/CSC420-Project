{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeMatches_SIFT(image1, image2):\n",
    "    ratio_thresh = 0.7\n",
    "    \n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    kp1, des1 = sift.detectAndCompute(image1,None)\n",
    "    kp2, des2 = sift.detectAndCompute(image2,None)\n",
    "    for row in range(des1.shape[0]):\n",
    "        des1[row] = des1[row]/np.linalg.norm(des1[row])\n",
    "    for row in range(des2.shape[0]):\n",
    "        des2[row] = des2[row]/np.linalg.norm(des2[row])\n",
    "    \n",
    "    bf = cv2.BFMatcher()\n",
    "    bf_matches = bf.knnMatch(des1,des2,k=2)\n",
    "    \n",
    "    matches = []\n",
    "    for m,n in bf_matches:\n",
    "        if m.distance < ratio_thresh * n.distance:\n",
    "            matches.append(m)\n",
    "    \n",
    "    return kp1, des1, kp2, des2, matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.researchgate.net/publication/314285930_Comparison_of_Feature_Detection_and_Matching_Approaches_SIFT_and_SURF\n",
    "# https://www.cs.ubc.ca/research/flann/uploads/FLANN/flann_pami2014.pdf\n",
    "\n",
    "def computeMatches_SURF(image1, image2):\n",
    "    minHessian = 400\n",
    "    ratio_thresh = 0.7\n",
    "\n",
    "    surf = cv2.xfeatures2d_SURF.create(hessianThreshold=minHessian)\n",
    "    kp1, des1 = surf.detectAndCompute(image1, None)\n",
    "    kp2, des2 = surf.detectAndCompute(image2, None)\n",
    "    for row in range(des1.shape[0]):\n",
    "        des1[row] = des1[row]/np.linalg.norm(des1[row])\n",
    "    for row in range(des2.shape[0]):\n",
    "        des2[row] = des2[row]/np.linalg.norm(des2[row])\n",
    "\n",
    "    fl_matcher = cv2.DescriptorMatcher_create(cv2.DescriptorMatcher_FLANNBASED)\n",
    "    knn_matches = fl_matcher.knnMatch(des1, des2, 2)\n",
    "\n",
    "    matches = []\n",
    "    for m,n in knn_matches:\n",
    "        if m.distance < ratio_thresh * n.distance:\n",
    "            matches.append(m)\n",
    "    \n",
    "    return kp1, des1, kp2, des2, matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://en.wikipedia.org/wiki/Random_sample_consensus\n",
    "\n",
    "def computeTrials(inNum, total_samples, num_samples, threshRatio):\n",
    "    ratio = inNum / total_samples\n",
    "    proportion = 1 - ratio ** num_samples\n",
    "    if proportion == 0:\n",
    "        return 1\n",
    "    if proportion == 1:\n",
    "        return np.inf\n",
    "    \n",
    "    return int(np.log(1-threshRatio) / np.log(proportion))\n",
    "    \n",
    "\n",
    "def ransac_affine(loc1, loc2, dist_threshold,\n",
    "           max_trials=1000, threshInNum=np.inf, threshLoss=0, threshRatio=0.99):\n",
    "\n",
    "    best_mat = None\n",
    "    best_inliers = None\n",
    "    bestInNum = 0\n",
    "    bestResLoss = np.inf\n",
    "    total_samples = loc1.shape[0]\n",
    "    \n",
    "    # take 3 points\n",
    "    indices = np.random.choice(total_samples, 3, replace=False)\n",
    "\n",
    "    \n",
    "    for num_trials in range(max_trials):\n",
    "        \n",
    "        # calculate affine transformation\n",
    "        src = np.array([loc1[idx] for idx in indices]).astype(np.float32)\n",
    "        dst = np.array([loc2[idx] for idx in indices]).astype(np.float32)\n",
    "        try:\n",
    "            warp_mat = cv2.getAffineTransform(src, dst)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        src3d = np.append(loc1, np.ones((loc1.shape[0], 1)), axis=1)\n",
    "        warp_dst3d = warp_mat @ src3d.T\n",
    "        warp_dst = warp_dst3d.T\n",
    "        \n",
    "        # compare dst points and targets\n",
    "        distance = np.linalg.norm(warp_dst - loc2, axis=1)\n",
    "        inliers = distance < dist_threshold\n",
    "        resLoss = np.sum(distance ** 2)\n",
    "        inNum = np.count_nonzero(inliers)\n",
    "        \n",
    "        new_max_trials = computeTrials(inNum, total_samples, 3, threshRatio)\n",
    "        \n",
    "        # update transformation matrix\n",
    "        if (inNum > bestInNum or (inNum == bestInNum and resLoss < bestResLoss)):\n",
    "            best_mat = warp_mat\n",
    "            bestInNum = inNum\n",
    "            bestResLoss = resLoss\n",
    "            best_inliers = inliers\n",
    "\n",
    "        if (bestInNum > threshInNum or bestResLoss < threshLoss or num_trials > new_max_trials):\n",
    "            break\n",
    "        \n",
    "        # resample\n",
    "        indices = np.random.choice(total_samples, 3, replace=False)\n",
    "\n",
    "    return best_mat, bestInNum/len(loc1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = cv2.imread('bridge1.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "image2 = cv2.imread('bridge2.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "image1 = cv2.resize(image1, (512, 512))\n",
    "image2 = cv2.resize(image2, (512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp1, des1, kp2, des2, matches = computeMatches_SURF(image1, image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = len(matches)\n",
    "loc1 = np.array([ kp1[matches[i].queryIdx].pt for i in range(num)])\n",
    "loc2 = np.array([ kp2[matches[i].trainIdx].pt for i in range(num)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_mat, _ = ransac_affine(loc1, loc2, dist_threshold=5, threshRatio=0.99)\n",
    "transformed = cv2.warpAffine(image1,best_mat,(image1.shape[1], image1.shape[0]))\n",
    "plt.imshow(transformed, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image2, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://en.wikipedia.org/wiki/Random_sample_consensus\n",
    "\n",
    "def ransac_perspective(loc1, loc2, dist_threshold,\n",
    "           max_trials=1000, threshInNum=np.inf, threshLoss=0, threshRatio=0.99):\n",
    "\n",
    "    best_mat = None\n",
    "    best_inliers = None\n",
    "    bestInNum = 0\n",
    "    bestResLoss = np.inf\n",
    "    total_samples = loc1.shape[0]\n",
    "    \n",
    "    # take 4 points\n",
    "    indices = np.random.choice(total_samples, 4, replace=False)\n",
    "\n",
    "    \n",
    "    for num_trials in range(max_trials):\n",
    "        \n",
    "        # calculate perspective transformation\n",
    "        src = np.array([loc1[idx] for idx in indices]).astype(np.float32)\n",
    "        dst = np.array([loc2[idx] for idx in indices]).astype(np.float32)\n",
    "        try:\n",
    "            warp_mat = cv2.getPerspectiveTransform(src, dst)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        src3d = np.append(loc1, np.ones((loc1.shape[0], 1)), axis=1)\n",
    "        warp_dst3d = warp_mat @ src3d.T\n",
    "        warp_dst3d[0] = np.divide(warp_dst3d[0], warp_dst3d[2])\n",
    "        warp_dst3d[1] = np.divide(warp_dst3d[1], warp_dst3d[2])\n",
    "        warp_dst = warp_dst3d.T[:, 0:2]\n",
    "        \n",
    "        # compare dst points and targets\n",
    "        distance = np.linalg.norm(warp_dst - loc2, axis=1)\n",
    "        inliers = distance < dist_threshold\n",
    "        resLoss = np.sum(distance ** 2)\n",
    "        inNum = np.count_nonzero(inliers)\n",
    "        \n",
    "        new_max_trials = computeTrials(inNum, total_samples, 4, threshRatio)\n",
    "        \n",
    "        # update transformation matrix\n",
    "        if (inNum > bestInNum or (inNum == bestInNum and resLoss < bestResLoss)):\n",
    "            best_mat = warp_mat\n",
    "            bestInNum = inNum\n",
    "            bestResLoss = resLoss\n",
    "            best_inliers = inliers\n",
    "\n",
    "        if (bestInNum > threshInNum or bestResLoss < threshLoss or num_trials > new_max_trials):\n",
    "            break\n",
    "        \n",
    "        # resample\n",
    "        indices = np.random.choice(total_samples, 4, replace=False)\n",
    "\n",
    "    return best_mat, bestInNum/len(loc1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://en.wikipedia.org/wiki/Random_sample_consensus\n",
    "\n",
    "def ransac_homography(loc1, loc2, dist_threshold,\n",
    "           max_trials=2000, threshInNum=np.inf, threshLoss=0, threshRatio=0.99):\n",
    "\n",
    "    best_mat = None\n",
    "    best_inliers = None\n",
    "    bestInNum = 0\n",
    "    bestResLoss = np.inf\n",
    "    total_samples = loc1.shape[0]\n",
    "    \n",
    "    # take 8 points\n",
    "    indices = np.random.choice(total_samples, 8, replace=False)\n",
    "\n",
    "    \n",
    "    for num_trials in range(max_trials):\n",
    "        \n",
    "        # calculate affine transformation\n",
    "        src = np.array([loc1[idx] for idx in indices]).astype(np.float32)\n",
    "        dst = np.array([loc2[idx] for idx in indices]).astype(np.float32)\n",
    "        try:\n",
    "            warp_mat = cv2.findHomography(src, dst)[0]\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        src3d = np.append(loc1, np.ones((loc1.shape[0], 1)), axis=1)\n",
    "        warp_dst3d = warp_mat @ src3d.T\n",
    "        warp_dst3d[0] = np.divide(warp_dst3d[0], warp_dst3d[2])\n",
    "        warp_dst3d[1] = np.divide(warp_dst3d[1], warp_dst3d[2])\n",
    "        warp_dst = warp_dst3d.T[:, 0:2]\n",
    "        \n",
    "        # compare dst points and targets\n",
    "        distance = np.linalg.norm(warp_dst - loc2, axis=1)\n",
    "        inliers = distance < dist_threshold\n",
    "        resLoss = np.sum(distance ** 2)\n",
    "        inNum = np.count_nonzero(inliers)\n",
    "        \n",
    "        new_max_trials = computeTrials(inNum, total_samples, 8, threshRatio)\n",
    "        \n",
    "        # update transformation matrix\n",
    "        if (inNum > bestInNum or (inNum == bestInNum and resLoss < bestResLoss)):\n",
    "            best_mat = warp_mat\n",
    "            bestInNum = inNum\n",
    "            bestResLoss = resLoss\n",
    "            best_inliers = inliers\n",
    "\n",
    "        if (bestInNum > threshInNum or bestResLoss < threshLoss or num_trials > new_max_trials):\n",
    "            break\n",
    "        \n",
    "        # resample\n",
    "        indices = np.random.choice(total_samples, 8, replace=False)\n",
    "    \n",
    "    print(num_trials)\n",
    "    return best_mat, bestInNum/len(loc1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mat, _ = ransac_homography(loc1, loc2, dist_threshold=1, threshRatio=0.99)\n",
    "transformed = cv2.warpPerspective(image1,best_mat,(image1.shape[1], image1.shape[0]))\n",
    "plt.imshow(transformed, cmap = \"gray\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
