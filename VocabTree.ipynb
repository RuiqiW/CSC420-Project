{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_pca = False\n",
    "\n",
    "# kmeans clusters\n",
    "num_clusters = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute features in all images from database\n",
    "\n",
    "des_list = []\n",
    "for path in image_paths:\n",
    "    image = cv2.imread(path)\n",
    "    surf = cv2.xfeatures2d.SURF_create()\n",
    "    kp, des = surf.detectAndCompute(image,None)\n",
    "    for row in range(des.shape[0]):\n",
    "        des[row] = des[row]/np.linalg.norm(des[row])\n",
    "    des_list.append((path, des))\n",
    "\n",
    "data_size = len(des_list)\n",
    "\n",
    "descriptors = des_list[0][1]\n",
    "for image, des in  des_list:\n",
    "    descriptors = np.vstack((descriptors, des))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "if perform_pca:\n",
    "    pca = PCA(n_components=40)\n",
    "    pca.fit(descriptors) \n",
    "    reduced_descriptors = pca.transform(descriptors)\n",
    "else:\n",
    "    reduced_descriptors = descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster the descriptors from the images in the database\n",
    "\n",
    "kmeans = KMeans(init='k-means++', n_clusters=num_clusters, n_init=10)\n",
    "kmeans.fit(reduced_descriptors)\n",
    "\n",
    "# code_book = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign each descriptor in database and query image to the closest cluster\n",
    "image_features = np.zeros((data_size, num_clusters))\n",
    "for i in range(data_size):\n",
    "    pred = kmeans.predict(des_list[i][1])\n",
    "    for k in range(len(pred)):\n",
    "        image_features[i][pred[k]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an inverted file index\n",
    "inverted_file_index = [[] for _ in range(num_clusters)]\n",
    "for i in range(data_size):\n",
    "    for k in range(num_clusters):\n",
    "        if(image_features[i][k] > 2):\n",
    "            inverted_file_index[k].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute a bag-of-words (BoW) vector for each retrieved image and query.\n",
    "# This vector just counts the number of occurrences of each word. It has as\n",
    "# many dimensions as there are visual words. Weight the vector with tf-idf.\n",
    "\n",
    "total_counts = np.sum( (test_features > 0) * 1, axis = 0)\n",
    "idf = np.log((1.0*data_size+1) / (1.0*total_counts + 1))\n",
    "\n",
    "weighted_features = image_features * idf.reshape(1, -1)\n",
    "\n",
    "for row in range(weighted_features.shape[0]):\n",
    "    weighted_features[row] = weighted_features[row]/np.linalg.norm(weighted_features[row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a query image, lookup all the visual words in the inverted file index to\n",
    "# get a list of images that share at least one visual word with the query\n",
    "def get_candidates(query_image):\n",
    "    kp, des = sift.detectAndCompute(query_image,None)\n",
    "    pred = kmeans.predict(des)\n",
    "    query_features = np.zeros((1, num_clusters))\n",
    "\n",
    "    for k in range(len(pred)):\n",
    "        query_features[0][pred[k]] += 1\n",
    "\n",
    "    candidates = []\n",
    "    for i in range(num_clusters):\n",
    "        if(query_features[0][i] > 2):\n",
    "            candidates.extend(inverted_file_index[i])\n",
    "    \n",
    "    candidates = list(set(candidates))\n",
    "    return query_features, candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute similarity between query BoW vector and all retrieved image BoW\n",
    "# vectors. Sort (highest to lowest). Take top K most similar images\n",
    "def getTopCandidates(top_k, query_features, candidates):\n",
    "    queryIdf = np.dot(idf, query_features)\n",
    "    queryIdf /= np.linalg.norm(queryIdf)\n",
    "    \n",
    "    # take candidate features\n",
    "    candidate_features = np.take(weighted_features, candidates)\n",
    "    similarity = candidate_features * queryIdf.reshape(1, -1)\n",
    "    \n",
    "    # get top k (large to small)\n",
    "    indices = np.argsort(-similarity)[0:top_k]\n",
    "    return np.array([candidates[idx] for idx in indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# candidates: image index of candidates\n",
    "query_features, candidates = get_candidates(query_image)\n",
    "\n",
    "top_k = 10\n",
    "# image index of top k candidates\n",
    "top_k_candidates = getTopCandidates(top_k, query_features, candidates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
